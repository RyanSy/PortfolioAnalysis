{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# ETL Pipeline",
   "id": "7b3f80bb32d4519b"
  },
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "import importlib\n",
    "from pathlib import Path\n",
    "import time\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "import helpers\n",
    "importlib.reload(helpers)\n",
    "from helpers import create_df, match_string\n",
    "\n",
    "import utils\n",
    "importlib.reload(utils)\n",
    "from utils import logger\n",
    "\n",
    "start_time = time.time()\n",
    "logger.info('ETL pipeline started...')\n",
    "\n",
    "# Set floats to 4 decimal places for extra precision in analysis.\n",
    "pd.set_option('display.float_format', lambda x: '%.4f' % x)\n",
    "\n",
    "account_positions_csv_file = Path().cwd().parent / 'data' / 'account_positions.csv'\n",
    "accounts_csv_file = Path().cwd().parent / 'data' / 'accounts.csv'\n",
    "price_history_csv_file = Path().cwd().parent / 'data' / 'price_history.csv'\n",
    "transactions_csv_file = Path().cwd().parent / 'data' / 'transactions.csv'\n",
    "\n",
    "# Create dataframes from csv files.\n",
    "account_positions = pd.read_csv(account_positions_csv_file)\n",
    "accounts = pd.read_csv(accounts_csv_file)\n",
    "price_history = pd.read_csv(price_history_csv_file)\n",
    "transactions = pd.read_csv(transactions_csv_file)\n",
    "logger.info('Dataframes created from .csv files.')"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "#====================================\n",
    "# Dimension account dataframe.\n",
    "#====================================\n",
    "dim_account = create_df('dim_account', accounts, ['account_id', 'user_name', 'first_name', 'last_name', 'account_type', 'created_at'], 'account_id') # Drop rows where account ID is NaN since no positions or transactions can be linked to them."
   ],
   "id": "c7c6cc8cf5ef1be9",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Fix typos in account types column.\n",
    "correct_account_types = ['joint', 'individual', 'retirement']\n",
    "\n",
    "for index in dim_account.index:\n",
    "    dim_account.loc[index, 'account_type'] = match_string(dim_account.loc[index, 'account_type'], correct_account_types)\n",
    "\n",
    "logger.info('Account type errors fixed.')"
   ],
   "id": "2624183e0c1fce8f",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "#=================================\n",
    "# Dimension date dataframe.\n",
    "#=================================\n",
    "# Extract all dates from all dataframes.\n",
    "account_position_dates = create_df('account_position_dates', account_positions, ['last_updated']).rename(columns={'last_updated': 'date'})\n",
    "account_dates = create_df('account_dates', accounts, ['created_at']).rename(columns={'created_at': 'date'})\n",
    "price_history_dates = create_df('price_history_dates', price_history, ['date'])\n",
    "transaction_dates = create_df('transaction_dates', transactions, ['trade_date']).rename(columns={'trade_date': 'date'})"
   ],
   "id": "8e2c23ab5fc1ac64",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Concatenate date dataframes to create master date dataframe.\n",
    "unique_dates = pd.concat([account_position_dates, account_dates, price_history_dates, transaction_dates]).drop_duplicates()\n",
    "\n",
    "# Create dimension date dataframe and reset index.\n",
    "dim_date = create_df('dim_date', unique_dates, ['date'], 'date', 'date').reset_index(drop=True)\n",
    "\n",
    "# Reset date ID.\n",
    "dim_date['date_id'] = dim_date.index + 1"
   ],
   "id": "a448b4ff23e6debe",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "#===================================\n",
    "# Dimension ticker dataframe.\n",
    "#===================================\n",
    "dim_ticker = create_df('dim_ticker', price_history, ['ticker_symbol'], None, 'ticker').reset_index(drop=True)"
   ],
   "id": "16fa17332d8312f8",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "#===================================\n",
    "# Fact account position dataframe.\n",
    "#===================================\n",
    "fact_account_position = create_df('fact_account_position', account_positions, ['account_id', 'ticker_symbol', 'shares_held', 'last_updated']) # Drop rows where account ID is NaN since no accounts or transactions can be linked to them."
   ],
   "id": "b343d78fa9f2e64f",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Drop rows with invalid tickers and save them to csv.\n",
    "# Extract numeric part and ensure it matches the exact format.\n",
    "numeric_part = fact_account_position['ticker_symbol'].str.extract(r'^stk(\\d+)$', expand=False)\n",
    "\n",
    "# Convert to numeric (handles NaN), then check the range.\n",
    "valid_mask = (\n",
    "    numeric_part.notna() &\n",
    "    (pd.to_numeric(numeric_part, errors='coerce').between(101, 500))\n",
    ")\n",
    "\n",
    "# Separate valid/invalid tickers, then save invalids to csv.\n",
    "valid_account_positions = fact_account_position[valid_mask]\n",
    "invalid_account_positons = fact_account_position[~valid_mask]\n",
    "invalid_account_positions_csv = Path().cwd().parent / 'data' / 'invalid' / 'invalid_account_positions.csv'\n",
    "invalid_account_positons.to_csv(invalid_account_positions_csv, index=False)\n",
    "\n",
    "# Set fact account position to valid positions.\n",
    "fact_account_position = valid_account_positions\n",
    "\n",
    "logger.info(f'{len(invalid_account_positons)} rows with invalid ticker symbols dropped from fact account position and saved to new csv file.')"
   ],
   "id": "5cdc2d9f42c40b59",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "#===================================\n",
    "# Fact price_history dataframe.\n",
    "#===================================\n",
    "fact_price_history = create_df('fact_price_history', price_history, list(price_history.columns))"
   ],
   "id": "905b7b12080c53bc",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "#===================================\n",
    "# Fact transaction dataframe.\n",
    "#===================================\n",
    "fact_transaction = create_df('fact_transaction', transactions, list(transactions.columns), None, 'transaction')"
   ],
   "id": "b2e7a40f429d4cde",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Fix typos in trade type column by defining regex and applying mask for each trade type.\n",
    "buy_regex = r'[buy]'\n",
    "sell_regex = r'[sell]'\n",
    "\n",
    "buy_mask = fact_transaction['trade_type'].str.contains(buy_regex, case=False, na=False)\n",
    "sell_mask = fact_transaction['trade_type'].str.contains(sell_regex, case=False, na=False)\n",
    "\n",
    "fact_transaction.loc[buy_mask, 'trade_type'] = 'buy'\n",
    "fact_transaction.loc[sell_mask & (~buy_mask), 'trade_type'] = 'sell'\n",
    "\n",
    "logger.info('Typos in trade type column fixed.')"
   ],
   "id": "cbd8ac2dfd8303e4",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Convert trade type to 'b' for 'buy' or 's' for 'sell.'\n",
    "fact_transaction['trade_type'] = fact_transaction['trade_type'].replace({'buy': 'b', 'sell': 's'})\n",
    "logger.info('Trade types replaced with single characters.')"
   ],
   "id": "4a131568f40878f6",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Convert columns to proper dtypes.\n",
    "fact_transaction = fact_transaction.astype({\n",
    "    'transaction_id': 'int32',\n",
    "    'account_id': 'int32',\n",
    "    'ticker_symbol': 'string',\n",
    "    'trade_type': 'category',\n",
    "    'shares': 'float64',\n",
    "    'price': 'float64'\n",
    "})"
   ],
   "id": "4f928b3398700fde",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "end_time = time.time()\n",
    "execution_time = end_time - start_time\n",
    "logger.info(f'âˆ´ ETL pipeline finished.\\nExecution time: {execution_time:.4f} seconds.')"
   ],
   "id": "a2c1ba03f81778a",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "---",
   "id": "fc626c35be87f226"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "#TODO:\n",
    "# Create csv files of bad/missing data.\n",
    "# Chane account type in dim account to i: individual, j: joint or r: retirement\n",
    "# Map values to IDs in dimension dataframes.\n",
    "# Rearrange columns to match schema.\n",
    "# Convert to correct dtypes."
   ],
   "id": "2dc311087256038e",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
